# 02 | 日志系统：一条SQL更新语句是如何执行的？
## 重要的日志模块：redo log
当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。

## 重要的日志模块：binlog

## 两种日志的不同
1. redo log 是 InnoDB 引擎特有的;binlog 是 MySQL 的 Server 层实现的,所有引擎都可 以使用。
2. redo log 是物理日志,记录的是“在某个数据页上做了什么修改”;binlog 是逻辑日志,记 录的是这个语句的原始逻辑,比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的,空间固定会用完;binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个,并不会覆盖以前的日志。

## 执行update操作的流程
1. 执行器先找引擎取 ID=2 这一行。ID 是主键,引擎直接用树搜索找到这一行。如果 ID=2 这 一行所在的数据页本来就在内存中,就直接返回给执行器;否则,需要先从磁盘读入内存, 然后再返回。
2. 执行器拿到引擎给的行数据,把这个值加上 1,比如原来是 N,现在就是 N+1,得到新的一 行数据,再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中,同时将这个更新操作记录到 redo log 里面,此时 redo log 处于 prepare 状态。然后告知执行器执行完成了,随时可以提交事务。
4. 执行器生成这个操作的 binlog,并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口,引擎把刚刚写入的 redo log 改成提交(commit)状态, 更新完成。

## 两阶段提交
### 为什么必须有“两阶段提交”呢?
这是为了让两份日志之间的逻辑一致

# 03 | 事务隔离:为什么你改了我还看不见?
事务问题|描述|解决方法
---|----|---
脏读|读到别的事务回滚前的数据。（读到了未提交）|“读提交”级别可解决
不可重复读 | 事务执行期间两次读到的数据不一样，因为读到了其他事务的修改。 | “可重复读”级别可以解决
幻读 | 当前事务第一次读到的数据比后来读到的数据少，因为其他事务又添加了数据 | “串行化”级别可以解决
1. 事务的特性:原子性、一致性、隔离性、持久性 
2. 多事务同时执行的时候,可能会出现的问题:脏读、不可重复读、幻读 
3. 事务隔离级别:读未提交、读提交、可重复读、串行化
4. 不同事务隔离级别的区别: 读未提交:一个事务还未提交,它所做的变更就可以被别的事务看到 读提交:一个事务提交之后,它所做的变更才可以被别的事务看到 可重复读:一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的 串行化:对应一个记录会加读写锁,出现冲突的时候,后访问的事务必须等前一个事务执行完 成才能继续执行
5. 配置方法:启动参数transaction-isolation 
6. 事务隔离的实现:每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统 中可以存在多个版本,这就是数据库的多版本并发控制(MVCC)。 
7. 回滚日志什么时候删除?系统会判断当没有事务需要用到这些回滚日志的时候,回滚日志 会被删除。 
8. 什么时候不需要了?当系统里没有比这个回滚日志更早的read-view的时候。 
9. 为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图,在这个事务提交之前,回滚记录都要保留,这会导致大量占用存储空间。除此之外,长事务还占用锁资
源,可能会拖垮库。
10. 事务启动方式:一、显式启动事务语句,begin或者start transaction,提交commit,回滚rollback;二、set autocommit=0,该命令会把这个线程的自动提交关掉。这样只要执行 一个select语句,事务就启动,并不会自动提交,直到主动执行commit或rollback或断开连接。
11. 建议使用方法一,如果考虑多一次交互问题,可以使用commit work and chain语法。在 autocommit=1的情况下用begin显式启动事务,如果执行commit则提交事务。如果执行com mit work and chain则提交事务并自动启动下一个事务。

# 04 索引上
(1)索引的出现就是为了提高数据查询效率,就像书的目录一样
(2)索引不但写在内存中,还写在硬盘中
(3)索引是存储引擎实现的
## 索引的常见模型
### 哈希表
以键-值(key-value)存储数据的结构 ~~把值放在数组里,用一个哈希函数把key换算成一个确定的位置,然后把value放在数组的 这个位置
#### 哈希冲突的处理办法
链表
#### 哈希表适用场景
只有等值查询的场景 
### 有序数组
按顺序存储。查询用二分法就可以快速查询,时间复杂度是:O(log(N)) 
#### 有序数组特点
有序数组查询效率高,更新效率低
#### 有序数组适用场景
有序数组的适用场景:静态存储引擎。 
### 搜索树
每个节点的左儿子小于父节点,父节点又小于右儿子。查询时间复杂度O(log (N)),更新时间复杂度O(log(N)) 
数据库存储大多不适用二叉树,因为树高过高,会适用N叉树
## Innodb的索引模型
在Innodb中,表都是根据主键顺序以索引的形式存放的,这种存储方式的表称为索引组织表。Innodb使用的B+树索引类型。每一个索引在InnoDB里面对应一棵B+树
### 索引类型
#### 主键索引(聚簇索引)
值存的是整行内容 
#### 非主键索引(二级索引,辅助索引)
值存的是主键内容
B+ 树能够很好地配合磁盘的读写特性,减少单次查询的磁盘访问次数 
## 基于主键索引和普通索引的查询有什么区别
(1)如果语句为select * from T where ID=500, 主键索引,只需要搜索ID这个B+树 (2)如果语句为select * from T where k = 5 , 普通索引,先查询k这个B+树,然后得到id的 值,再搜索ID这个B+树,这个过程叫做回表 **非主键索引需要多扫描一棵索引树,所以尽量用主键索引
## 索引维护
### B+树为了维护索引的有序性,所以需要做索引维护
#### 页分裂、页合并。 
页分裂使空间利用率降低了50%。 一个数据页满了,按照B+Tree算法,新增加一个数据页,叫做页分裂,会导致性能下降。 空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据页合并,合并的 过程是分裂过程的逆过程
### 自增主键的使用场景 
1. 主键长度越小,普通索引的叶子节点就越小,普通索引占用的空间也就越小 
2. 业务字段做主键场景:1:只有一个索引 2:该索引必须是唯一索引 这是典型的kv场景 由于没有其他索引,估不用考虑其它索引叶子节点大小的问题,故将该值设为主键索引

# 05 | 深入浅出索引(下)
## 回表
回到主键索引树搜索的过程,称为回表 
## 覆盖索引
某索引已经覆盖了查询需求,称为覆盖索引,例如:select ID from T where k b etween 3 and 5 在引擎内部使用覆盖索引在索引K上其实读了三个记录,R3~R5(对应的索引k上的记录项), 但对于MySQL的Server层来说,它就是找引擎拿到了两条记录,因此MySQL认为扫描行数 是2
## 最左前缀原则
B+Tree这种索引结构,可以利用索引的"最左前缀"来定位记录 只要满足最左前缀,就可以利用索引来加速检索。 最左前缀可以是联合索引的最左N个字段,也可以是字符串索引的最左M个字符 
### 建立联合索引时,如何安排索引内的字段顺序？
第一原则是:如果通过调整顺序,可以少维护一个索引,那么这个顺序往往就是需要优先考虑 采用的。 
## 索引下推
在MySQL5.6之前,只能从根据最左前缀查询到ID开始一个个回表。到主键索引 上找出数据行,再对比字段值。 MySQL5.6引入的索引下推优化,可以在索引遍历过程中,对索引中包含的字段先做判断, 直接过滤掉不满足条件的记录,减少回表次数。
# 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？
根据加锁范围：MySQL里面的锁可以分为：全局锁、表级锁、行级锁
## 全局锁：
对整个数据库实例加锁。
MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL)
这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。
使用场景：全库逻辑备份。
风险：
1. 如果在主库备份，在备份期间不能更新，业务停摆
2. 如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟

官方自带的逻辑备份工具mysqldump，当mysqldump使用参数--single-transaction的时候，会启动一个事务，确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。

一致性读是好，但是前提是引擎要支持这个隔离级别。

如果要全库只读，为什么不使用set global readonly=true的方式？
1. 在有些系统中，readonly的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。
2. 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。
## 表级锁
MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)
### 表锁
表锁的语法是:lock tables ... read/write
可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。
### 元数据锁(meta data lock,MDL)
MDL：不需要显式使用，在访问一个表的时候会被自动加上。

MDL的作用：保证读写的正确性。

在对一个表做增删改查操作的时候，加MDL读锁；

当要对表做结构变更操作的时候，加MDL写锁。

读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。

MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

# 07 | 行锁功过：怎么减少行锁对性能的影响？
## 两阶段锁
在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
### 建议
如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
## 死锁
当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。
### 解决方案
1. 通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB引擎默认值是50s。
2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）。
## 如何解决热点行更新导致的性能问题？
1. 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用
2. 控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
3. 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。

innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。

# 08 | 事务到底是隔离的还是不隔离的?
innodb支持RC和RR隔离级别实现是用的一致性视图(consistent read view)

事务在启动时会拍一个快照,这个快照是基于整个库的. 基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)
如果在事务内select t表,另外的事务执行了DDL t表,根据发生时间,要嘛锁住要嘛报错(参考第六章)
## 事务是如何实现的MVCC呢?
1. 每个事务都有一个事务ID,叫做transaction id(严格递增) 
2. 事务在启动时,找到已提交的最大事务ID记为up_limit_id。 
3. 事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的row trx_id写到undolog里,并且在数据页上把id的值改为2,并且把修改这条语句的transaction id记在该行行头 
4. 再定一个规矩,一个事务要查看一条数据时,必须先用该事务的up_limit_id与该行的transaction id做比对,如果up_limit_id>=transaction id,那么可以看.如果up_limit_id<transaction id,则只能去undo log里去取。去undo log查找数据的时候,也需要做比对,必须up_limit_id>transaction id,才返回数据
4.什么是当前读,由于当前读都是先读后写,只能读当前的值,所以为当前读.会更新事务内的up_limit_id为该事务的transaction id
5.为什么rr能实现可重复读而rc不能,分两种情况 (1)快照读的情况下,rr不能更新事务内的up_limit_id, 而rc每次会把up_limit_id更新为快照读之前最新已提交事务的transaction id,则rc不能可重复读
(2)当前读的情况下,rr是利用record lock+gap lock来实现的,而rc没有gap,所以rc不能可重复 读